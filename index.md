---
layout: single
title: ""
permalink: /
author_profile: true
---

I lead research on **AI security and trustworthy machine learning**, with a focus on **adversarial attacks and defenses, robustness under deployment constraints, and secure perception systems**. My work bridges **theory, system-level design, and real-world evaluation**, targeting vision, autonomous, embedded, and multimodal AI systems.

---

## ğŸ”¥ News

- **2026.01**: ğŸ‰ 2 papers accepted at **ICLR 2026**
- **2025.11**: ğŸ‰ 1 paper accepted at **DATE 2026**
- **2025.10**: ğŸ‰ Selected as Top Reviewer at **NeurIPS 2025** 
- **2025.06**: ğŸ‰ 1 paper accepted at **ICCV 2025**
- **2024.06**: ğŸ‰ 1 paper accepted at **IROS 2024**
- **2024.06**: ğŸ‰ 3 papers accepted at **ICIP 2024**
- **2024.02**: ğŸ‰ 1 paper accepted at **CVPR 2024**
- **2024.02**: ğŸ‰ 1 paper accepted at **DAC 2024** 


---

## Research Overview

My research aims to **advance the security, robustness, and trustworthiness of machine learning systems** under adversarial threats and realistic deployment constraints. I study how **architecture choices (e.g., Vision Transformers), quantization and approximation, physical-world effects, and multimodal interactions** shape both vulnerabilities and defenses. A recurring theme in my work is **breaking brittle alignment**â€”semantic, gradient, or representationalâ€”to improve robustness while preserving efficiency and deployability.

---

## Selected Research Projects

Below are representative research projects spanning adversarial machine learning, robustness, and secure AI systems.  

---

<!-- DRIFT -->
<div style="display:flex; gap:28px; margin-bottom:50px; align-items:flex-start;">

  <div style="min-width:260px; max-width:260px;">
    <img src="/images/drift.png" style="width:100%; border-radius:8px;">
  </div>

  <div>

    <div style="font-size:1.4rem; font-weight:700; margin-bottom:8px;">
      ICLR 2026: 
      <a href="/project_pages/drift/">DRIFT: Divergent Response in Filtered Transformations</a>
    </div>

    <div style="font-size:1rem; line-height:1.6; margin-bottom:12px; text-align:justify;">
      DRIFT is a stochastic ensemble defense that disrupts gradient consensus across transformations, significantly reducing adversarial transferability while preserving clean accuracy.
    </div>

    <div>
      <a href="/project_pages/drift/">Project</a> |
      <a href="#">Paper</a>
    </div>

  </div>
</div>

---

<!-- TriQDef -->
<div style="border:1px solid #e5e7eb; border-radius:12px; padding:14px;">
<a href="/project_pages/triqdef/">
<img src="/images/triqdef.png" style="width:100%; border-radius:10px; margin-bottom:10px;">
</a>

<div style="font-weight:700; font-size:1.05rem;">
TriQDef
</div>

<div style="font-size:0.9rem; opacity:0.85;">
Quantized Patch Defense (ICLR 2026)
</div>

<p style="font-size:0.95rem;">
Disrupts semantic and gradient alignment across quantized models to prevent patch transferability.
</p>

<a href="/project_pages/triqdef/">Project Page â†’</a>
</div>

---
<!-- TESSER -->
<div style="display:flex; gap:28px; margin-bottom:50px; align-items:flex-start;">

  <div style="min-width:260px; max-width:260px;">
    <img src="/images/tesser_overview.png" style="width:100%; border-radius:8px; margin-bottom:8px;">
  </div>

  <div>

    <div style="font-size:1.4rem; font-weight:700; margin-bottom:8px;">
      NeurIPS 2026: 
      <a href="/project_pages/tesser/">TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers</a>
    </div>

    <div style="font-size:1rem; line-height:1.6; margin-bottom:12px; text-align:justify;">
      TESSER introduces spectral and semantic regularization to enhance adversarial transferability from Vision Transformers to CNNs and hybrid architectures, achieving state-of-the-art black-box attack performance across diverse model families.
    </div>

    <div>
      <a href="/project_pages/tesser/">Project</a> |
      <a href="https://arxiv.org/abs/2505.19613">Paper</a>
    </div>

  </div>
</div>

---

<!-- DAP -->
<div style="display:flex; gap:28px; margin-bottom:50px; align-items:flex-start;">

  <div style="min-width:260px; max-width:260px;">
    <img src="/images/dap_overview.png" style="width:100%; border-radius:8px;">
  </div>

  <div>

    <div style="font-size:1.4rem; font-weight:700; margin-bottom:8px;">
      CVPR 2024: 
      <a href="/project_pages/dap/">DAP: Dynamic Adversarial Patch</a>
    </div>

    <div style="font-size:1rem; line-height:1.6; margin-bottom:12px; text-align:justify;">
      DAP proposes an adaptive adversarial patch that dynamically adjusts spatial placement and appearance to evade person detectors under real-world transformations.
    </div>

    <div>
      <a href="/project_pages/dap/">Project</a> |
      <a href="#">Paper</a>
    </div>

  </div>
</div>


---

## ğŸ† Awards & Honors

- **Outstanding Reviewer**, NeurIPS 2025  
- **Best Senior Researcher Award**, eBRAIN Lab, NYU Abu Dhabi (2023)  
- **Erasmus+ Scholarship** (2019)  
- **DAAD Scholarships**: ATIoT (2018), Young ESEM Program (2016)

---

## ğŸ§‘â€ğŸ« Academic Service & Community

- Reviewer: ICLR, NeurIPS, ICCV, CVPR, AAAI, ECCV, DAC, DATE, ICIP; IEEE TIFS, TCAD, TCSVT  
- Tutorial Organizer & Speaker: *ML Security in Autonomous Systems*, IROS 2024  

---

## ğŸ“¬ Contact & Links

- **Email**: ag9321@nyu.edu  

I am always open to collaborations on **AI security, adversarial robustness, and trustworthy ML systems**.
